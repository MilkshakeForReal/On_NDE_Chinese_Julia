# 1.1.1 上手

**准备知识** 我们将自始至终假设读者熟悉ODEs的基础知识和现代深度学习的基础知识，但我们不会假设对这两者有深入了解。基于我们的许多读者可能来自传统的应用数学背景，而没有过多地接触过深度学习，那么[附录A](../../fu-lu-a/)也提供了我们将假设的相关深度学习概念的总结。它还提供了更多关于深度学习的参考资料。

关于神经SDEs的内容将假定对SDEs的熟悉程度。

除了这些（相对较弱的）假设，我们将在需要时介绍一些概念。文本的不同部分将触及诸如粗糙路径理论或微分方程的数值方法等主题。在每一种情况下，我们都假定读者对这些课题不甚熟悉，并在必要时提供参考资料以了解更多的情况。

下一章（关于神经ODEs）努力明确说明甚至是 "基本 "的细节，如常微分方程的解的存在性，或使用交叉熵作为损失函数。后面各章的复杂程度越来越高，建议按顺序阅读。

> 译者建议看完第一章和第二章后先看第五章。

**代码** 强烈鼓励对应用这些技术感兴趣的读者 编写一些示例代码。每一章都包含一些数值例子——通常是在玩具数据集上，以便于理解。相应的代码都是可用的，并且有很好的文档：它们可以在Diffrax软件库的例子中找到，该库是为JAX框架编写的。确实使用求解微分方程和对它求微分的标准软件库使得和神经微分方程工作变得简单。这些将在第5.6节讨论（包括Diffrax和其他框架的选择）。这些库同样有很好的文档，并包含大量的例子。

> 中文版将会使用Julia编写的[DifferentialEquations.jl](https://diffeq.sciml.ai/stable/)和[DiffEqFlux.jl](https://diffeqflux.sciml.ai/stable/).

**实验** 这里的材料着重于介绍NDE的理论；相应地，我们的数值例子将倾向于选择玩具数据集，以方便理解。 这些技术在现实世界中（可能是非常大规模的）的应用可以在原始论文中找到，这些论文在本文的每个主题下被引用。

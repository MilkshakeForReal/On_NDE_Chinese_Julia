# 3. MNIST图像分类

### 导入相关库

```julia
using Lux
using ComponentArrays, CUDA, DiffEqSensitivity, NNlib, Optimisers, OrdinaryDiffEq, Random,
      Statistics, Zygote
import MLDatasets: MNIST
import MLDataUtils: convertlabel, LabelEnc
import MLUtils: DataLoader, splitobs
CUDA.allowscalar(false)
```

这里，`Lux` 是我们要使用的深度学习框架，它的好处在于每个神经网络层都是纯函数，参数是显式传入的，我们会看到这样的代码

```
y, st = model(x,ps,st)
```

这里`x` 是输入，`ps` 是参数，`st` 是状态，它用来记录一些信息，例如方差等。这样的好处是将多个神经层的参数打包成一个向量很容易，方便用于Neural ODE计算梯度。

### 加载数据集

\`\`\`Use MLDataUtils LabelEnc for natural onehot conversion

function onehot(labels\_raw) return convertlabel(LabelEnc.OneOfK, labels\_raw, LabelEnc.NativeLabels(collect(0:9))) end

function loadmnist(batchsize, train\_split) # Load MNIST: Only 1500 for demonstration purposes N = 1500 imgs = MNIST.traintensor(1:N) labels\_raw = MNIST.trainlabels(1:N)

```
# Use MLDataUtils LabelEnc for natural onehot conversion
function onehot(labels_raw)
    return convertlabel(LabelEnc.OneOfK, labels_raw, LabelEnc.NativeLabels(collect(0:9)))
end

function loadmnist(batchsize, train_split)
    # Load MNIST: Only 1500 for demonstration purposes
    N = 1500
    imgs = MNIST.traintensor(1:N)
    labels_raw = MNIST.trainlabels(1:N)

    # Process images into (H,W,C,BS) batches
    x_data = Float32.(reshape(imgs, size(imgs, 1), size(imgs, 2), 1, size(imgs, 3)))
    y_data = onehot(labels_raw)
    (x_train, y_train), (x_test, y_test) = splitobs((x_data, y_data); at=train_split)

    return (
            # Use DataLoader to automatically minibatch and shuffle the data
            DataLoader(collect.((x_train, y_train)); batchsize=batchsize, shuffle=true),
            # Don't shuffle the test data
            DataLoader(collect.((x_test, y_test)); batchsize=batchsize, shuffle=false))
end
```

这段代码不用看。

#### 定义NeuralODE

```julia
struct NeuralODE{M <: Lux.AbstractExplicitLayer, So, Se, T, K} <:
       Lux.AbstractExplicitContainerLayer{(:model,)}
    model::M
    solver::So
    sensealg::Se
    tspan::T
    kwargs::K
end
```

解释：

* &#x20;`model` : 表示微分方程右端的神经网络
* `solver` ：表示ODE求解器
* `sensealg` ：表示计算灵敏度的办法。也就是我们在[5.1](../5.-shen-jing-wei-fen-fang-cheng-shu-zhi-jie/5.1-chuan-guo-odes-de-fan-xiang-chuan-bo.md)节提到的各种算法。
* `tspan` : 时间区间
* `kwargs` : 这里放一些`solver` 的关键字参数，比如容忍度。

接下来我们定义构造函数

```julia
function NeuralODE(model::Lux.AbstractExplicitLayer;
                   solver=Tsit5(),
                   sensealg=InterpolatingAdjoint(; autojacvec=ZygoteVJP()),
                   tspan=(0.0f0, 1.0f0),
                   kwargs...)
    return NeuralODE(model, solver, sensealg, tspan, kwargs)
end
```

这里的`InterpolatingAdjoint(; autojacvec=ZygoteVJP())` 就是[5.1.2.4](../5.-shen-jing-wei-fen-fang-cheng-shu-zhi-jie/5.1-chuan-guo-odes-jin-hang-fan-xiang-chuan-bo/5.1.2-xian-you-hua-zai-li-san/5.1.2.4-cha-zhi-ban-sui.md)节中的插值伴随，而参数`ZygoteVJP()` 表示用`Zygote` 这个自动微分库计算伴随矩阵的右端。

接下来定义前向传播函数

```julia
function (n::NeuralODE)(x, ps, st)
    function dudt(u, p, t)
        u_, st = n.model(u, p, st)
        return u_
    end
    prob = ODEProblem{false}(ODEFunction{false}(dudt), x, n.tspan, ps)
    return solve(prob, n.solver; sensealg=n.sensealg, n.kwargs...), st
end
```

这里的代码是不言自明的：我们定义动力学，打包成ODEProblem，然后传给求解器。

> `ODEfunction{false}` 表示它Out-Of-Place定义的，具体见[文档](https://diffeq.sciml.ai/stable/types/ode\_types/#SciMLBase.ODEFunction)

求解完毕之后，会返回一个\`ODESolution\`对象，我们要把它转化成数组

```julia
function diffeqsol_to_array(x::ODESolution{T, N, <:AbstractVector{<:CuArray}}) where {T, N}
    return dropdims(gpu(x); dims=3)  #如果使用GPU
end
diffeqsol_to_array(x::ODESolution) = dropdims(Array(x); dims=3) #如果使用CPU
```

### 创建和初始化模型

```julia
function create_model()
    # Construct the Neural ODE Model
    model = Chain(FlattenLayer(),
                  Dense(784, 20, tanh),
                  NeuralODE(Chain(Dense(20, 10, tanh), Dense(10, 10, tanh),
                                  Dense(10, 20, tanh));
                            save_everystep=false,
                            reltol=1.0f-3,
                            abstol=1.0f-3,
                            save_start=false),
                  diffeqsol_to_array,
                  Dense(20, 10))

    rng = Random.default_rng()
    Random.seed!(rng, 0)

    ps, st = Lux.setup(rng, model)
    ps = ComponentArray(ps) |> gpu
    st = st |> gpu

    return model, ps, st
end
```


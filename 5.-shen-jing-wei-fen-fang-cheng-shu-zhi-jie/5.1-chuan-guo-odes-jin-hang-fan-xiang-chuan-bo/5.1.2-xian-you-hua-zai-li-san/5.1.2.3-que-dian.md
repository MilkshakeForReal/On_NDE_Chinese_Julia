# 5.1.2.3 缺点

**计算成本**  连续伴随法需要额外的计算来重新计算$$y(t)$$；这意味着一个稍慢的和更昂贵的计算过程。

**截断误差**  第二个缺点是数值离散化误差：前向计算的$$y(t)$$值（从初始条件$$y(0)$$开始计算）和后向计算的$$y(t)$$值（从前向获得的终端条件$$y(T)$$的数值近似开始计算）会有差异。 此外，除了$$y(t)$$的重新计算外，$$a_y(t)$$和$$a_\theta(t)$$的连续伴随方程本身也必须进行数值求解，这样做会产生一些额外的数值误差。 其结果是，通过连续伴随法计算的梯度不会像直接对求解器反向传播计算的梯度那样精确。(这是黄金标准，与实际使用的模型相对应。)这意味着训练可能更慢，最终的模型性能可能受到影响，在最坏的情况下，训练可能完全失败。\[GKB19]描述了连续伴随法可能的失败模式，\[OR20]进行了全面的经验调查，比较了先优化后离散和先离散后优化，支持后者的观点。

**例5.6.**  考虑用数值ODE求解器求解系统$$\frac{\mathrm{d} y}{\mathrm{~d} t}(t)=\lambda y(t)$$，其中$$y(t)∈R$$，$$y(0) = y_0$$，并假设$$λ<0$$。大多数微分方程求解器--那些具有非平凡稳定域的求解器\[HW02，定义2.1]--可以顺利处理，因为误差会以指数形式衰减。然而，当这个问题从$$y(T)$$向后求解时，如方程(5.2)，那么小的误差反而会被指数地放大。此外，如果$$λ>$$0，那么只需将上述讨论中的前向和后向互换一下，也会出现同样的问题。

**然而......**  尽管有这些可怕的警告，连续伴随法在实践中往往（但并不总是）仍然有效，不需要任何特别的照顾。连续伴随法对任何特定问题的适用性通常是由经验决定的--"训练似乎是有效的吗？"——而困难往往不是从业者的关注点。

